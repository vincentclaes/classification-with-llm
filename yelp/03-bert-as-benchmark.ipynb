{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbff05ae10750b97",
   "metadata": {},
   "source": [
    "# BERT as Benchmark\n",
    "\n",
    "- Fine tune BERT model using autotrain from Huggingface: https://huggingface.co/autotrain\n",
    "- Used the train.csv and val.csv in the autotrain job\n",
    "- Use default configuration\n",
    "- Fine-tuned model : https://huggingface.co/vincentclaes/autotrain-0br8k-gdjpm\n",
    "- accuracy: 0.9994418604651163\n",
    "\n",
    "## Run against test dataset and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7485f556da24cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T08:54:06.413063Z",
     "start_time": "2024-09-21T08:54:04.652519Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7ce459bb0f4ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T09:57:31.160714Z",
     "start_time": "2024-09-21T09:57:30.204222Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/vincent/Workspace/classification_with_llm/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the model (if you're using the model from the Hugging Face Hub)\n",
    "classifier_zero_shot = pipeline('zero-shot-classification', model='google-bert/bert-base-uncased', truncation=True)\n",
    "classifier_fine_tuned = pipeline('text-classification', model='vincentclaes/autotrain-yelp-2likv', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54db095c7a6b831a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T10:05:15.469445Z",
     "start_time": "2024-09-21T09:57:32.541927Z"
    }
   },
   "outputs": [],
   "source": [
    "# read test.csv, and make prediction for the column 'question' and add the result to the column 'predicted_class_name'\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# LABELS = [\"1 star review\", \"2 star review\", \"3 star review\", \"4 star review\", \"5 star review\"]\n",
    "LABEL_MAPPING = {1: \"1 star review\", 2: \"2 star review\", 3: \"3 star review\", 4: \"4 star review\", 5: \"5 star review\"}\n",
    "\n",
    "df_zero_shot = df.copy()\n",
    "df_zero_shot['predicted_class_name'] = df_zero_shot['question'].apply(lambda x: classifier_zero_shot(x, candidate_labels=list(LABEL_MAPPING.keys()))[\"labels\"][0])\n",
    "\n",
    "df_fine_tuned = df.copy()\n",
    "df_fine_tuned['predicted_class_name'] = df_fine_tuned['question'].apply(lambda x: classifier_fine_tuned(x)[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac7ca9bf7b74e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T11:46:40.341752Z",
     "start_time": "2024-09-21T11:46:39.428487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18666666666666668\n",
      "Zero-Shot Accuracy: {'accuracy': 0.18666666666666668}\n",
      "Accuracy: 0.29904761904761906\n",
      "Fine-Tuned Accuracy: {'accuracy': 0.29904761904761906}\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(df):\n",
    "    from datasets import load_metric\n",
    "    \n",
    "    metric = load_metric(\"accuracy\")\n",
    "    accuracy = metric.compute(predictions=df['predicted_class_name'], references=df['class_name'])\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy['accuracy']}\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "zero_shot_acc = calculate_accuracy(df_zero_shot)\n",
    "print(f\"Zero-Shot Accuracy: {zero_shot_acc}\")\n",
    "fine_tuned_acc = calculate_accuracy(df_fine_tuned)\n",
    "print(f\"Fine-Tuned Accuracy: {fine_tuned_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0d21fffbcd4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
